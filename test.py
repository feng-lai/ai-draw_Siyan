import os
import re
import requests
from urllib.parse import urlparse
import hashlib
import mimetypes
import json
import time

def extract_links(vue_filepath):
    """æå–æ‰€æœ‰åª’ä½“å±æ€§ä¸­çš„è¿œç¨‹URL"""
    with open(vue_filepath, 'r', encoding='utf-8') as file:
        content = file.read()
    
    # åŒ¹é…æ‰€æœ‰å¯èƒ½çš„åª’ä½“å±æ€§ï¼ˆsrc, href, poster, data-srcç­‰ï¼‰
    pattern = r'''(?:src|href|poster|data-src|data-poster|source)\s*=\s*["'](http[s]?://[^"']+)["']'''
    links = re.findall(pattern, content)
    return content, list(set(links))  # å»é‡

def get_extension_from_content_type(content_type, default='.bin'):
    """æ ¹æ®Content-Typeè·å–æ–‡ä»¶æ‰©å±•å"""
    if not content_type:
        return default
    
    # å¸¸è§ç±»å‹æ˜ å°„
    type_map = {
        'image/jpeg': '.jpg',
        'image/png': '.png',
        'image/gif': '.gif',
        'image/webp': '.webp',
        'image/svg+xml': '.svg',
        'video/mp4': '.mp4',
        'video/webm': '.webm',
        'video/ogg': '.ogv',
        'audio/mpeg': '.mp3',
        'audio/ogg': '.ogg',
        'application/javascript': '.js',
        'text/css': '.css',
        'application/json': '.json',
        'text/html': '.html',
    }
    
    # ä¼˜å…ˆä½¿ç”¨æ˜ å°„è¡¨
    if content_type in type_map:
        return type_map[content_type]
    
    # ä½¿ç”¨mimetypesä½œä¸ºåå¤‡
    ext = mimetypes.guess_extension(content_type)
    return ext or default

def download_links(links, save_dir):
    """ä¸‹è½½æ‰€æœ‰é“¾æ¥å¹¶è¿”å›æœ¬åœ°è·¯å¾„æ˜ å°„"""
    os.makedirs(save_dir, exist_ok=True)
    local_paths = {}
    
    # åˆ›å»ºä¸‹è½½æ—¥å¿—
    log_path = os.path.join(save_dir, 'download_log.json')
    if os.path.exists(log_path):
        with open(log_path, 'r', encoding='utf-8') as f:
            download_log = json.load(f)
    else:
        download_log = {}
    
    # åªä¸‹è½½åª’ä½“æ–‡ä»¶ç±»å‹
    MEDIA_TYPES = [
        'image/jpeg', 'image/png', 'image/gif', 'image/webp', 'image/svg+xml',
        'video/mp4', 'video/webm', 'video/ogg', 'audio/mpeg', 'audio/ogg'
    ]
    
    for url in links:
        try:
            # æ£€æŸ¥æ—¥å¿—ä¸­æ˜¯å¦å·²æœ‰è®°å½•
            if url in download_log:
                local_paths[url] = download_log[url]
                print(f"â© ä½¿ç”¨ç¼“å­˜: {url}")
                continue
                
            # è·å–æ–‡ä»¶åå’Œæ‰©å±•å
            parsed_url = urlparse(url)
            filename_base = os.path.basename(parsed_url.path) or hashlib.md5(url.encode()).hexdigest()
            
            # å‘é€HEADè¯·æ±‚è·å–å†…å®¹ç±»å‹
            head_resp = requests.head(url, timeout=10, allow_redirects=True)
            content_type = head_resp.headers.get('Content-Type', '').split(';')[0]
            ext = get_extension_from_content_type(content_type)
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯åª’ä½“æ–‡ä»¶ç±»å‹
            if content_type not in MEDIA_TYPES:
                print(f"â­ï¸ è·³è¿‡éåª’ä½“æ–‡ä»¶: {url} ({content_type})")
                continue
                
            # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
            filename = f"{hashlib.md5(url.encode()).hexdigest()}{ext}"
            local_path = os.path.join(save_dir, filename)
            
            print(f"â¬‡ï¸ æ­£åœ¨ä¸‹è½½: {url} ({content_type})")
            
            # ä¸‹è½½æ–‡ä»¶
            response = requests.get(url, timeout=15, stream=True)
            response.raise_for_status()
            
            with open(local_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    f.write(chunk)
            
            # è®°å½•åˆ°æ˜ å°„å’Œæ—¥å¿—
            local_paths[url] = f"/downloaded_images/{filename}"
            download_log[url] = local_paths[url]
            
            print(f"âœ… ä¸‹è½½æˆåŠŸ: {filename}")
            time.sleep(0.5)  # é¿å…è¯·æ±‚è¿‡å¿«
            
        except Exception as e:
            print(f"âŒ ä¸‹è½½å¤±è´¥ {url}: {str(e)[:100]}")
    
    # ä¿å­˜ä¸‹è½½æ—¥å¿—
    with open(log_path, 'w', encoding='utf-8') as f:
        json.dump(download_log, f, indent=2)
    
    return local_paths

def replace_links_in_content(content, link_map):
    """æ›¿æ¢æ–‡ä»¶å†…å®¹ä¸­çš„æ‰€æœ‰åŒ¹é…é“¾æ¥"""
    # æŒ‰URLé•¿åº¦é™åºæ’åºï¼Œé¿å…éƒ¨åˆ†æ›¿æ¢
    sorted_urls = sorted(link_map.keys(), key=len, reverse=True)
    
    # æ”¯æŒçš„æ‰€æœ‰å±æ€§
    attributes = ['src', 'href', 'poster', 'data-src', 'data-poster']
    
    for original_url in sorted_urls:
        local_path = link_map[original_url]
        
        # å¤„ç†ä¸åŒå¼•ç”¨æ–¹å¼
        for attr in attributes:
            # æ„å»ºæ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
            patterns = [
                rf'{attr}=["\']{re.escape(original_url)}["\']',
                rf'{attr}=\s*["\']{re.escape(original_url)}["\']',
            ]
            
            for pattern in patterns:
                # æŸ¥æ‰¾å¹¶æ›¿æ¢
                matches = re.findall(pattern, content)
                if matches:
                    replacement = f'{attr}="{local_path}"'
                    content = re.sub(pattern, replacement, content)
    
    return content

def main():
    script_dir = os.path.dirname(os.path.abspath(__file__))
    vue_filename = os.path.abspath(os.path.join(
        script_dir, '..', 'ai-draw_Siyan', 'src', 'pages', 'ImageEditor.vue'
    ))
    
    # èµ„æºä¿å­˜åˆ°public/downloaded_images
    save_dir = os.path.abspath(os.path.join(
        script_dir, '..', 'ai-draw_Siyan', 'public', 'downloaded_images'
    ))
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(save_dir, exist_ok=True)
    
    print(f"ğŸ“„ å¤„ç†æ–‡ä»¶: {vue_filename}")
    content, links = extract_links(vue_filename)
    
    if not links:
        print("âš ï¸ æœªå‘ç°è¿œç¨‹é“¾æ¥")
        return
    
    print(f"ğŸ”— å‘ç° {len(links)} ä¸ªè¿œç¨‹åª’ä½“é“¾æ¥")
    local_paths = download_links(links, save_dir)
    
    if not local_paths:
        print("âŒ æ— æœ‰æ•ˆä¸‹è½½ï¼Œç»ˆæ­¢")
        return
    
    # åˆ›å»ºå¤‡ä»½
    #backup_path = f"{vue_filename}.bak"
   # if not os.path.exists(backup_path):
      #  with open(backup_path, 'w', encoding='utf-8') as f:
      #      f.write(content)
       # print(f"ğŸ“¦ å·²åˆ›å»ºå¤‡ä»½: {backup_path}")
    
    # æ›¿æ¢å†…å®¹
    updated_content = replace_links_in_content(content, local_paths)
    
    # å†™å…¥æ›´æ–°
    with open(vue_filename, 'w', encoding='utf-8') as f:
        f.write(updated_content)
    
    print(f"âœ… æ›¿æ¢å®Œæˆ! {len(local_paths)} ä¸ªèµ„æºå·²æœ¬åœ°åŒ–")
    print(f"ğŸ“ èµ„æºç›®å½•: {save_dir}")
    print(f"ğŸ“ ä¸‹è½½æ—¥å¿—: {os.path.join(save_dir, 'download_log.json')}")

if __name__ == "__main__":
    main()